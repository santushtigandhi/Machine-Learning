{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "honest-finder",
   "metadata": {},
   "source": [
    "We will be starting with the most basic and simplest algorithm today, that is Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-lindsay",
   "metadata": {},
   "source": [
    "<b>Logistic Regression</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-substitute",
   "metadata": {},
   "source": [
    "Have you ever wondered whether to buy or not to buy an item? <br>\n",
    "We often deal with the situations where we need to choose between different sets of things. For example, whether we want to buy something or not, is it going to be sunny, windy or rainy today? <br>\n",
    "All these come under this classification where we predict, which set of a particular data point belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-tournament",
   "metadata": {},
   "source": [
    "We generally use Logistic Regression when we gave to deal with the discrete values like \"yes\" or \"no\", \"0\" or \"1\" or like tossing a coin which would result in only two outcomes -\"head\" or \"tails\".<br>\n",
    "It predicts the probability of the occurence of the event by fitting data into logit function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-deputy",
   "metadata": {},
   "source": [
    "In statistics, the logit function is a function associated with the standard logistic distribution. It has many uses in data analysis and machine learning, especially in data transformations.\n",
    "\n",
    "Mathematically, the logit is the inverse of the standard logistic function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-effects",
   "metadata": {},
   "source": [
    "The logistic function is a sigmoid function (common S shaped curve)<br>\n",
    "- Sigmoid Function is constrained by a pair of horizontal assimtotes as x tends to +∞(infinity) to -∞(infinity). <br>\n",
    "- The curve is generally convex for values less than zero and concave for values more than zero. <br>\n",
    "- Active region of a sigmoid is -5 to +5. <br>\n",
    "- It is monotonic (a function varying in such a way that it either never decreases or never increases) and has first derivative which is bell-shaped. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-valuation",
   "metadata": {},
   "source": [
    "<img src=\"https://andymath.com/wp-content/uploads/2019/08/Logistic-Function.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-carrier",
   "metadata": {},
   "source": [
    "In the above formula - if L=1, k=-1 and (x-x0)=0 then it is known as <b>Standard Logistic Function.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-professional",
   "metadata": {},
   "source": [
    "So, the logit function is defined as : <br>\n",
    "<img src=\"https://miro.medium.com/max/1400/1*UkAxAuEG8TkTlIl1buLY6A.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-hayes",
   "metadata": {},
   "source": [
    "Because of this, the logit is also called the log-odds since it is equal to the logarithm of the odds ratio (p/1-p), where p is a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-chassis",
   "metadata": {},
   "source": [
    "In regression analysis, logistic regression is estimating the parameters of a logistic model. Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass/fail which is represented by an indicator variable, where the two values are labeled \"0\" and \"1\". <br>\n",
    "The corresponding probability of the value labeled \"1\" can vary between 0 (certainly the value \"0\") and 1 (certainly the value \"1\"), hence the labeling; the function that converts log-odds to probability is the logistic function, hence the name. The unit of measurement for the log-odds scale is called a logit, from logistic unit, hence the alternative names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-tactics",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1244/1*vEiAxU_mVmFIOvf-xzTolw.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-trail",
   "metadata": {},
   "source": [
    "Logistic regression is a process of modeling the probability of a discrete outcome given an input variable. The most common logistic regression models a binary outcome; something that can take two values such as true/false, yes/no, and so on. Multinomial logistic regression can model scenarios where there are more than two possible discrete outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-welsh",
   "metadata": {},
   "source": [
    " The logistic function applies a sigmoid function to restrict the y value from a large scale to within the range 0–1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-polymer",
   "metadata": {},
   "source": [
    "It is used when our dependent variable is dichotomous or binary. It just means a variable that has only 2 outputs, for example, if a person will survive the accident or not, the student will pass this exam or not. The outcome can either be yes or no (2 outputs). This regression technique is similar to linear regression and can be used to predict the Probabilities for classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-worship",
   "metadata": {},
   "source": [
    "Now let's discuss the mathematics behind Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-camera",
   "metadata": {},
   "source": [
    "<img src=\"Page1.jpeg\">\n",
    "<img src=\"Page2.jpeg\">\n",
    "<img src=\"Page3.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-carnival",
   "metadata": {},
   "source": [
    "Let's now start with the code. We will also be starting with our first dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-airplane",
   "metadata": {},
   "source": [
    "It's a very simple dataset which consist of features like 'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction' and 'Age'. Here we have our target feature as 'Outcome' which is having dicrete values like \"0\" and \"1\" where 0 means not having diabetes and 1 means having diabetes. Now we will try to predict whether a person has diabetes or not based on the features mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-railway",
   "metadata": {},
   "source": [
    "<b>Step 1 : Importing the libraries needed.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "certified-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score\n",
    "\n",
    "import warnings  #we generally do this step so that if we ever encounter any warning given by any algorithm it simply ignores it.\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-schedule",
   "metadata": {},
   "source": [
    "<b>Step 2 : Describing the columns of our dataset.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "answering-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            1       85             66             29        0  26.6   \n",
       "1            8      183             64              0        0  23.3   \n",
       "2            1       89             66             23       94  28.1   \n",
       "3            0      137             40             35      168  43.1   \n",
       "4            5      116             74              0        0  25.6   \n",
       "5            3       78             50             32       88  31.0   \n",
       "6           10      115              0              0        0  35.3   \n",
       "7            2      197             70             45      543  30.5   \n",
       "8            8      125             96              0        0   0.0   \n",
       "9            4      110             92              0        0  37.6   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.351   31        0  \n",
       "1                     0.672   32        1  \n",
       "2                     0.167   21        0  \n",
       "3                     2.288   33        1  \n",
       "4                     0.201   30        0  \n",
       "5                     0.248   26        1  \n",
       "6                     0.134   29        0  \n",
       "7                     0.158   53        1  \n",
       "8                     0.232   54        1  \n",
       "9                     0.191   30        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age','Outcome']\n",
    "df = pd.read_csv(\"diabetes.csv\", names = col, header = 1) #here we have used a variable df so as to store our csv file. Instead of reading the file again and again by using pandas we store that in a variable so that, whenever we need to use the dataframe we can use it by this variable.\n",
    "df.head(n =10) #Here we are printing the first 10 entries of our dataset. Here \"n\" denotes the number of entries you want to fetch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upper-haiti",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "757            1      106             76              0        0  37.5   \n",
       "758            6      190             92              0        0  35.5   \n",
       "759            2       88             58             26       16  28.4   \n",
       "760            9      170             74             31        0  44.0   \n",
       "761            9       89             62              0        0  22.5   \n",
       "762           10      101             76             48      180  32.9   \n",
       "763            2      122             70             27        0  36.8   \n",
       "764            5      121             72             23      112  26.2   \n",
       "765            1      126             60              0        0  30.1   \n",
       "766            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "757                     0.197   26        0  \n",
       "758                     0.278   66        1  \n",
       "759                     0.766   22        0  \n",
       "760                     0.403   43        1  \n",
       "761                     0.142   33        0  \n",
       "762                     0.171   63        0  \n",
       "763                     0.340   27        0  \n",
       "764                     0.245   30        0  \n",
       "765                     0.349   47        1  \n",
       "766                     0.315   23        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(n=10) #This is similar to head but here we are printing the last 10 entries of our dataset. Here \"n\" denotes the number of entries you want to fetch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "balanced-mandate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.842243</td>\n",
       "      <td>120.859192</td>\n",
       "      <td>69.101695</td>\n",
       "      <td>20.517601</td>\n",
       "      <td>79.903520</td>\n",
       "      <td>31.990482</td>\n",
       "      <td>0.471674</td>\n",
       "      <td>33.219035</td>\n",
       "      <td>0.348110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.370877</td>\n",
       "      <td>31.978468</td>\n",
       "      <td>19.368155</td>\n",
       "      <td>15.954059</td>\n",
       "      <td>115.283105</td>\n",
       "      <td>7.889091</td>\n",
       "      <td>0.331497</td>\n",
       "      <td>11.752296</td>\n",
       "      <td>0.476682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   767.000000  767.000000     767.000000     767.000000  767.000000   \n",
       "mean      3.842243  120.859192      69.101695      20.517601   79.903520   \n",
       "std       3.370877   31.978468      19.368155      15.954059  115.283105   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   32.000000   \n",
       "75%       6.000000  140.000000      80.000000      32.000000  127.500000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  767.000000                767.000000  767.000000  767.000000  \n",
       "mean    31.990482                  0.471674   33.219035    0.348110  \n",
       "std      7.889091                  0.331497   11.752296    0.476682  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243500   24.000000    0.000000  \n",
       "50%     32.000000                  0.371000   29.000000    0.000000  \n",
       "75%     36.600000                  0.625000   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() #We are describing the dataset here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-survey",
   "metadata": {},
   "source": [
    "<b>Step 3 : Represent your datatset graphically so that it would be easier to analyse. (The more you represent your datatset graphically, the more you will understand your dataset)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-turkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Outcome', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Outcome',data=df) #Here, we plotted count plot so as to understand the data properly. We plotted the Outcome column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-repository",
   "metadata": {},
   "source": [
    "<b>Step 4 : Finally defining your X(independent variables) and Y(dependent variable)</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "referenced-pointer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Outcome',axis=1) #All the features are our dependent variables here. Hence, instead of writing the names of all the features we generally write it like this. (taking all the features except outcome, that's why we are dropping that column)\n",
    "y = df.Outcome #As Independent feature is Outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-equity",
   "metadata": {},
   "source": [
    "<b>Step 5 : Splitting your dataset into training and testing set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "breeding-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.15,random_state =42) #Since we have mentioned the test size here so the train size will automatically be taken as 1 - 0.15 = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-ordinary",
   "metadata": {},
   "source": [
    "Now you must be confused what is random_state and why have I used it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-making",
   "metadata": {},
   "source": [
    "Random state ensures that the splits that you generate are reproducible. Scikit-learn uses random permutations to generate the splits. The random state that you provide is used as a seed to the random number generator,so that your train-test splits are always deterministic. If you don't set a seed, it is different each time. This ensures that the random numbers are generated in the same order. <br>\n",
    "If you don't specify the random_state in the code, then every time you run(execute) your code a new random value is generated and the train and test datasets would have different values each time.<br>\n",
    "However, if a fixed value is assigned like random_state = 0 or 1 or 42 or any other integer then no matter how many times you execute your code the result would be the same .i.e, same values in train and test datasets. <br>\n",
    "Since at every run, train data will change so the accuracy might change for every run. When the Random_state = \" constant integer\" is defined then train data will be constant for every run so that it will make easy to debug.<br>\n",
    "I have used 42 as random_state, if we want we can choose other numbers as well because the act of setting the random_state parameter is more important than what number we set it to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "peripheral-evanescence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=101, solver='newton-cg')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='newton-cg',penalty='l2',random_state=101,C=1.0) #Here we are applying our algorithm.\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-princess",
   "metadata": {},
   "source": [
    "While using Logistic Regression, I have used some parameters like – solver, penalty and C. Now, explaining these terms: Comparison of the sparsity (percentage of zero coefficients) of solutions when L1, L2 and Elastic-Net penalty are used for different values of C. We can see that large values of C give more freedom to the model. Conversely, smaller values of C constrain the model more. A high value of C tells the model to give high weight to the training data, and a lower weight to the complexity penalty. A low value tells the model to give more weight to this complexity penalty at the expense of fitting to the training data. <br>\n",
    "L2 regularization adds an L2 penalty equal to the square of the magnitude of coefficients. L2 will not yield sparse models and all coefficients are shrunk by the same factor (none are eliminated). <br>\n",
    "And the last parameter, which is solver=’newton-cg’, we used this solver because it supports the L2 regularization which we are using in penalty parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-gibraltar",
   "metadata": {},
   "source": [
    "Why have I used these parameters?<br>\n",
    "Because in some cases they generally increase the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latin-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_test) #Here, we are predicting the values of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rapid-fraud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  0.8275862068965517\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is: \",accuracy_score(y_test, y_pred)) #This line tells us the accuracy of our model comparing the actual values (y_test) and predicated values by our model (y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-arthur",
   "metadata": {},
   "source": [
    "We completed our first algorithm today. <br>\n",
    "Keep practising, download the datasets from kaggle and get started!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
